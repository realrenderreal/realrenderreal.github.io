<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Real2Render2Real</title>
  <link rel="icon" href="data/r2r2r-icon.ico" type="image/x-icon">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    :root {
      /*
        To change the overall background color of the website, adjust --bg below.
        For a subtle off-white, try #f9f9f9, #f7f7fa, or #fcfcfc.
      */
      --accent: #3478f6;
      --bg: #f6f5f2;
      --text: #111;
      --sidebar-bg: #f6f5f2;
      --sidebar-text: #555;
      --sidebar-active: var(--accent);
      --title-font: 'Inter', system-ui, sans-serif;
      --body-font: 'Inter', system-ui, sans-serif;
      --sidebar-width: max(20vw, 180px);
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: var(--body-font);
      background-color: var(--bg);
      color: var(--text);
      display: flex;
      scroll-behavior: smooth;
      font-size: 1.08rem;
      line-height: 1.6;
    }

    .sidebar {
      width: var(--sidebar-width);
      position: fixed;
      height: 100vh;
      overflow-y: auto;
      background: var(--sidebar-bg);
      border: none;
      padding: 2rem 1rem;
      text-align: right;
    }

    .sidebar h2 {
      font-size: 1.25rem;
      margin-bottom: 1rem;
      color: var(--text);
    }

    .sidebar ul {
      list-style: none;
      padding: 0;
    }

    .sidebar ul li {
      margin-bottom: 0.75rem;
    }

    .sidebar a {
      text-decoration: none;
      color: var(--sidebar-text);
      font-weight: 500;
      transition: color 0.25s, font-weight 0.25s, text-shadow 0.25s;
    }

    .sidebar a.active,
    .sidebar a:hover {
      color: var(--sidebar-active);
      font-weight: 700;
      text-shadow: 0 2px 8px rgba(52,120,246,0.10), 0 1px 0 #fff;
      text-decoration: none;
    }

    main {
      /* margin-left: var(--sidebar-width); */
      margin: auto;
      width: calc(80% - var(--sidebar-width));
      max-width: 1000px;
      padding: 0 2rem;
      box-sizing: border-box;
    }

    section {
      margin-bottom: 3rem;
    }

    h1, h2 {
      color: #1a1a1a;
      font-family: var(--title-font);
      font-weight: 700;
      letter-spacing: -0.5px;
    }

    h1 {
      font-size: 2.1rem;
      margin-bottom: 0.5rem;
    }

    h2 {
      font-size: 1.35rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
    }

    .main-title {
      font-size: 4rem;
      font-weight: 800;
      font-family: var(--title-font);
      margin-bottom: 0.2rem;
      margin-top: 0.5rem;
      line-height: 1.1;
      letter-spacing: -1px;
      text-align: left;
      color: #111;
    }

    .main-title .gradient {
      background: linear-gradient(90deg, #cf60d3 0%, #7221ff 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      color: transparent;
      font-weight: 900;
    }

    .subtitle {
      font-size: 1.95rem;
      font-weight: 500;
      color: #222;
      margin-bottom: 1.1rem;
      line-height: 1.3;
      text-align: left;
    }

    .video-carousel {
      display: flex;
      overflow-x: auto;
      gap: 0.75rem;
      padding: 0.5rem 4px;
      max-width: min(1000px, calc(100vw - 240px));
      width: 100%;
      margin: 0 auto;
      box-sizing: border-box;
      white-space: nowrap;
    }

    .video-carousel video {
      width: 240px;
      border-radius: 4px;
      border: 1px solid #ccc;
      flex-shrink: 0;
    }

    .iframe-pair {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-top: 1rem;
      justify-content: center;
    }

    .iframe-pair iframe {
      flex: 1 1 48%;
      height: 400px;
      border: 1px solid #ccc;
      border-radius: 4px;
    }

    img {
      max-width: 100%;
      border-radius: 4px;
      box-shadow: 0 0 8px rgba(0,0,0,0.1);
      /* border: 1px solid #ccc; */
    }

    pre {
      background: #23272e;
      color: #f8f8f2;
      padding: 1rem;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.92em;
      border: 1px solid #181a1f;
    }

    code {
      color: #f8f8f2;
    }

    footer {
      text-align: center;
      font-size: 0.9rem;
      color: #888;
      padding: 1rem;
    }

    video, iframe {
      box-shadow: 0 0 8px rgba(0,0,0,0.1);
    }

    .selected-thumb {
      box-shadow: 0 0 8px rgba(52,120,246,0.18), 0 0 8px rgba(0,0,0,0.12);
      z-index: 2;
    }

    @media (max-width: 900px) {
      .sidebar {
        display: none;
      }
      :root {
        --sidebar-width: 0;
      }
      main {
        margin-left: 0;
        max-width: 100vw;
        width: 100vw;
        padding: 0;
      }
      .main-content {
        max-width: 100vw;
        width: 100vw;
        padding: 0 8px;
      }
      .video-carousel {
        max-width: 100vw;
        padding: 0.5rem 8px;
      }
      .main-title {
        font-size: 2.4rem !important;
      }
    }

    .main-content {
      max-width: 100% !important;
      width: 100vw;
      padding: 0 30px;
    }

    .iframe-container {
      position: relative;
      width: 100%;
      max-width: 100%;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    .click-and-move-overlay {
      position: absolute;
      top: 8%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: rgba(255,255,255,0.85);
      border-radius: 4px;
      padding: 0.5rem 1.2rem;
      box-shadow: 0 0 8px rgba(0,0,0,0.08);
      z-index: 10;
      pointer-events: none;
      display: flex;
      align-items: center;
      font-size: 1.15rem;
      font-weight: 550;
      color: #222;
      gap: 0.5rem;
    }
    .click-and-move-overlay .inline-image {
      height: 1.5em;
      vertical-align: middle;
      margin: 0 0.2em;
    }

    .carousel-hint {
      text-align: center;
      color: #666;
      font-size: 0.98rem;
      margin-bottom: 0.3rem;
      margin-top: 0.2rem;
      font-weight: 500;
      letter-spacing: 0.01em;
    }

    .carousel-wrapper {
      position: relative;
      width: 100%;
      max-width: min(1000px, calc(100vw - 240px));
      margin: 0 auto;
      display: flex;
      align-items: center;
    }
    .carousel-arrow {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background: rgba(255,255,255,0.85);
      border: 1px solid #ccc;
      border-radius: 50%;
      width: 36px;
      height: 36px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.5rem;
      color: #3478f6;
      cursor: pointer;
      z-index: 5;
      box-shadow: 0 0 8px rgba(0,0,0,0.08);
      transition: background 0.2s;
      user-select: none;
    }
    .carousel-arrow:hover {
      background: #f0f4ff;
    }
    .carousel-arrow.left {
      left: -18px;
    }
    .carousel-arrow.right {
      right: -18px;
    }

  </style>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const links = document.querySelectorAll('.sidebar a');
      const sections = Array.from(document.querySelectorAll('main section'));

      function updateActiveLink() {
        const scrollY = window.scrollY + 100;
        let current = sections[0];

        for (const section of sections) {
          if (section.offsetTop <= scrollY) {
            current = section;
          }
        }

        links.forEach(link => {
          link.classList.remove('active');
          if (link.getAttribute('href') === `#${current.id}`) {
            link.classList.add('active');
          }
        });
      }

      window.addEventListener('scroll', updateActiveLink);
      updateActiveLink();

      // Iframe carousel logic
      const iframeCarousel = document.getElementById('iframe-carousel');
      const iframeLabel = document.getElementById('iframe-carousel-label');
      const prevBtn = document.getElementById('iframe-carousel-prev');
      const nextBtn = document.getElementById('iframe-carousel-next');
      const iframeData = [
        {
          src: 'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/faucet_recording_20250507_110111.viser&initialCameraPosition=1.026,0.455,0.651&initialCameraLookAt=0.108,-0.143,-0.040&initialCameraUp=-0.000,-0.000,1.000',
          label: 'Faucet Turn'
        },
        {
          src: 'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/package_recording_20250507_103622.viser&initialCameraPosition=1.050,0.428,0.670&initialCameraLookAt=0.000,0.000,0.000&initialCameraUp=-0.000,-0.000,1.000',
          label: 'Package Open'
        },
        {
          src: 'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/drawer_reversed_demo.viser&initialCameraPosition=1.050,0.428,0.700&initialCameraLookAt=0.000,0.000,-0.100&initialCameraUp=-0.000,-0.000,1.000',
          label: 'Drawer Pull'
        },
        {
          src: 'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/coffee_maker_recording_20250506_191701.viser&initialCameraPosition=1.009,0.430,0.637&initialCameraLookAt=0.240,-0.160,-0.081&initialCameraUp=-0.000,-0.000,1.000',
          label: 'Mug Place'
        },
        {
          src: 'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/tiger_pick_r2r2r_recording_20250507_112639.viser&initialCameraPosition=1.027,0.445,0.681&initialCameraLookAt=0.188,-0.113,-0.129&initialCameraUp=-0.000,-0.000,1.000',
          label: 'Tiger Pick'
        },
      ];
      let iframeIdx = 0;
      function updateIframeCarousel() {
        iframeCarousel.src = iframeData[iframeIdx].src;
        iframeLabel.textContent = iframeData[iframeIdx].label;
      }
      if (prevBtn && nextBtn && iframeCarousel && iframeLabel) {
        prevBtn.addEventListener('click', () => {
          iframeIdx = (iframeIdx - 1 + iframeData.length) % iframeData.length;
          updateIframeCarousel();
        });
        nextBtn.addEventListener('click', () => {
          iframeIdx = (iframeIdx + 1) % iframeData.length;
          updateIframeCarousel();
        });
      }

      // Main iframe swap logic for thumbnails
      const mainIframe = document.getElementById('main-iframe');
      const thumbnailVideos = document.querySelectorAll('#iframe-thumbnails video');
      const iframeSrcs = [
        'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/faucet_recording_20250507_110111.viser&initialCameraPosition=1.026,0.455,0.651&initialCameraLookAt=0.108,-0.143,-0.040&initialCameraUp=-0.000,-0.000,1.000',
        'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/cardboard_box_recording_20250507_103622.viser&initialCameraPosition=1.050,0.428,0.670&initialCameraLookAt=0.000,0.000,0.000&initialCameraUp=-0.000,-0.000,1.000',
        'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/drawer_recording_20250507_104056.viser&initialCameraPosition=1.050,0.428,0.700&initialCameraLookAt=0.000,0.000,-0.100&initialCameraUp=-0.000,-0.000,1.000',
        'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/coffee_maker_recording_20250506_191701.viser&initialCameraPosition=1.009,0.430,0.637&initialCameraLookAt=0.240,-0.160,-0.081&initialCameraUp=-0.000,-0.000,1.000',
        'https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/tiger_pick_r2r2r_recording_20250507_112639.viser&initialCameraPosition=1.027,0.445,0.681&initialCameraLookAt=0.188,-0.113,-0.129&initialCameraUp=-0.000,-0.000,1.000',
      ];
      if (mainIframe && thumbnailVideos.length === iframeSrcs.length) {
        thumbnailVideos.forEach((vid, idx) => {
          vid.addEventListener('click', () => {
            mainIframe.src = iframeSrcs[idx];
            // Highlight the selected video
            thumbnailVideos.forEach(v => { v.style.outline = ''; v.classList.remove('selected-thumb'); });
            vid.style.outline = '3px solid var(--accent)';
            vid.classList.add('selected-thumb');
          });
        });
        // Highlight the first by default
        thumbnailVideos[0].style.outline = '3px solid var(--accent)';
        thumbnailVideos[0].classList.add('selected-thumb');
      }

      // Physical rollouts main video selector logic
      const mainPhysicalVideo = document.getElementById('main-physical-video');
      const physicalThumbnails = document.querySelectorAll('#physical-video-thumbnails video');
      if (mainPhysicalVideo && physicalThumbnails.length > 0) {
        physicalThumbnails.forEach((vid, idx) => {
          vid.addEventListener('click', () => {
            const src = vid.getAttribute('data-video');
            if (src) {
              const prevTime = mainPhysicalVideo.currentTime;
              mainPhysicalVideo.querySelector('source').src = src;
              mainPhysicalVideo.load();
              // Set currentTime after metadata is loaded
              mainPhysicalVideo.onloadedmetadata = () => {
                try {
                  mainPhysicalVideo.currentTime = prevTime;
                } catch (e) {}
                mainPhysicalVideo.play();
              };
              // Highlight selected
              physicalThumbnails.forEach(v => { v.style.outline = ''; v.classList.remove('selected-thumb'); });
              vid.style.outline = '3px solid var(--accent)';
              vid.classList.add('selected-thumb');
            }
          });
        });
        // Highlight the first by default
        physicalThumbnails[0].style.outline = '3px solid var(--accent)';
        physicalThumbnails[0].classList.add('selected-thumb');
      }

      // Carousel arrow button logic for both carousels
      function setupCarouselArrows(carouselId, leftBtnId, rightBtnId, videoSelector, selectCallback) {
        const carousel = document.getElementById(carouselId);
        const leftBtn = document.getElementById(leftBtnId);
        const rightBtn = document.getElementById(rightBtnId);
        const videos = carousel ? Array.from(carousel.querySelectorAll(videoSelector)) : [];
        let selectedIdx = videos.findIndex(v => v.classList.contains('selected-thumb'));
        if (selectedIdx === -1) selectedIdx = 0;
        function selectAt(idx) {
          if (idx < 0 || idx >= videos.length) return;
          videos[idx].click();
          videos[idx].scrollIntoView({ behavior: 'smooth', inline: 'center', block: 'nearest' });
          selectedIdx = idx;
        }
        if (leftBtn) {
          leftBtn.onclick = () => {
            selectAt((selectedIdx - 1 + videos.length) % videos.length);
          };
        }
        if (rightBtn) {
          rightBtn.onclick = () => {
            selectAt((selectedIdx + 1) % videos.length);
          };
        }
        // Update selectedIdx on manual click/scroll
        videos.forEach((v, idx) => {
          v.addEventListener('click', () => { selectedIdx = idx; });
        });
      }
      setupCarouselArrows('physical-video-thumbnails', 'physical-carousel-left', 'physical-carousel-right', 'video', null);
      setupCarouselArrows('iframe-thumbnails', 'iframe-carousel-left', 'iframe-carousel-right', 'video', null);
    });
  </script>
</head>
<body>
  <nav class="sidebar">
    
    <ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#realrollouts">Real Robot Rollouts</a></li>
<li><a href="#scaling">Performance Scaling</a></li>
<li><a href="#reconstruction">Approach</a></li>
<li><a href="#iframes">Embodiment Agnostic Data</a></li>
<li><a href="#randomization">Data Distribution</a></li>
<li><a href="#trajectories">Trajectory Interpolation</a></li>
<li><a href="#description-video">Full Project Video</a></li>
<li><a href="#bibtex">BibTeX</a></li>
    </ul>
  </nav>
  <main>
    <div class="main-content">
    <section id="title-block">
      <div style="margin-top: 20px;"></div>
      <div class="main-title"><span>Real2</span><span class="gradient">Render</span><span>2Real</span></div>
      <div class="subtitle">Scaling Robotic Manipulation Data Without Dynamics Simulation or Robot Hardware</div>
      <p style="font-size: 1.1rem; margin-bottom: 0.1rem; color: #000;">
        <a href="https://uynitsuj.github.io/about/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Justin Yu*</a>,
        <a href="https://max-fu.github.io/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Letian Fu*</a>,
        <a href="https://qingh097.github.io/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Huang Huang</a>,
        <a href="https://el-refai.github.io/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Karim El-Refai</a>,
        <a href="https://www.tri.global/about-us/dr-rares-ambrus" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Rares Ambrus</a>,
        <a href="" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Richard Cheng</a>,
        <a href="https://zubairirshad.com/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Muhammad Zubair Irshad</a>,
        <a href="https://goldberg.berkeley.edu/" target="_blank" style="color: #000; text-decoration: none; transition: text-decoration 0.3s;" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">Ken Goldberg</a>
      </p>

      <p style="font-size: 1rem; margin-top: 3px; margin-bottom: -5px; display: flex; justify-content: space-between;"><span><b>UC Berkeley</b>, <b>Toyota Research Institute</b></span><span style="font-style: italic;">* Equal contribution</span></p>
    </section>

    <section id="overview-video">
      <div style="display: flex; justify-content: center; width: 100%; margin: 1rem 0;">
        <video autoplay muted loop playsinline style="width: 100%; max-width: 900px; border-radius: 4px; border: 1px solid #ccc;">
          <source src="data/twitter-final-compress.mp4" type="video/mp4">
        </video>
      </div>
      <div style="max-width: 900px; margin: 0 auto 1.5rem auto; font-size: 1.15rem; color: #222; text-align: center;">
        <b>Real2Render2Real (R2R2R)</b> is a scalable pipeline for generating data to train generalist manipulation policies - without dynamics simulation or teleoperation.
      </div>
      <div style="max-width: 900px; margin: 0 auto 1.5rem auto; font-size: 1.15rem; color: #222; text-align: center;">
        View the full project video <a href="#description-video">here</a>.
      </div>
      <div style="text-align: center; margin-bottom: 2.5rem;">
        <a href="data/Real2Render2Real.pdf" style="margin-right: 1.5rem; color: #3478f6; text-decoration: none; font-weight: 600;">[Paper]</a>
        <a href="https://arxiv.org/abs/2505.09601" style="margin-right: 1.5rem; color: #3478f6; text-decoration: none; font-weight: 600;">[arXiv]</a>
        <a href="https://github.com/uynitsuj/real2render2real" style="color: #3478f6; text-decoration: none; font-weight: 600;">[Code]</a>
      </div>
      <div style="max-width: 900px; margin: 0 auto 1.3rem auto; font-style: italic; font-size: 1.15rem; color: #222; text-align: center;">
        We train modern RGB + Proprioception based imitation learning frameworks and VLA models (Vanilla Diffusion Policy, π<sub>0</sub>-FAST); without requiring any teleoperation data!
      </div>
    </section>

    <section id="abstract">
      <h1><span class="toggle-btn" onclick="toggleAbstract()">Abstract &#9662</span><span id="expand-hint" style="font-size: 0.8rem; margin-left: 8px; color: #424242;">(click to expand)</span></h1>
      <div id="abstract-content" style="display: none; max-height: 0; overflow: hidden; transition: max-height 0.5s ease-out;">
        Scaling robot learning requires vast and diverse datasets. Yet
        the prevailing data collection paradigm—human teleoperation—remains costly
        and constrained by manual effort and physical robot access. We introduce
        <b>Real2Render2Real (R2R2R)</b>, a scalable pipeline for generating robot training
        data without physics simulation or teleoperation. Using a smartphone-captured
        scan of one or more objects and a single monocular human demonstration, R2R2R
        reconstructs detailed 3D object geometry and appearance, tracks 6-DoF object motion, and synthesizes thousands of physically plausible, robot-agnostic demonstrations through parallel-environment photorealistic rendering and inverse kinematics.
        Data generated by R2R2R integrates directly with models that operate on
        robot proprioceptive states and image observations, such as vision-language-action
        models (VLA) and imitation learning policies. Physical experiments suggest that
        models trained on R2R2R data alone can achieve comparable performance to those
        trained on teleoperated demonstrations, with model performance scaling with the
        amount and diversity of R2R2R data, while requiring <b>1/27</b> of the time to generate.
        By decoupling data generation from physical robot constraints, R2R2R enables the
        computational scaling of robot datasets to support increasingly capable generalist
        policies.
      </div>
      <script>
        function toggleAbstract() {
          const content = document.getElementById('abstract-content');
          const btn = document.querySelector('.toggle-btn');
          const hint = document.getElementById('expand-hint');
          if (content.style.display === 'none') {
            content.style.display = 'block';
            setTimeout(() => {
              content.style.maxHeight = content.scrollHeight + "px";
            }, 10);
            btn.innerHTML = 'Abstract &#9652';
            hint.style.display = 'none'; // Hide the hint after expanding
          } else {
            content.style.maxHeight = '0';
            setTimeout(() => {
              content.style.display = 'none';
            }, 500); // Wait for transition to complete
            btn.innerHTML = 'Abstract &#9662';
          }
        }
      </script>
    </section>
    
    <section id="realrollouts">
        <h2>Real Robot Rollouts</h2>
        <div style="display: flex; justify-content: center; width: 100%; margin-bottom: 1rem;">
          <video id="main-physical-video" autoplay muted loop playsinline style="width: 100%; max-width: 900px; border-radius: 4px; border: 1px solid #ccc;">
            <source src="data/real_vids/faucet_real_5x_side.mp4" type="video/mp4">
          </video>
        </div>
        <div class="carousel-wrapper">
          <div class="carousel-arrow left" id="physical-carousel-left">&#8592;</div>
          <div class="video-carousel" id="physical-video-thumbnails">
            <video data-video="data/real_vids/faucet_real_5x_side.mp4" autoplay muted loop playsinline src="data/real_vids/faucet_real_5x_side.mp4" style="cursor:pointer;"></video>
            <video data-video="data/real_vids/mug_real_5x_side.mp4" autoplay muted loop playsinline src="data/real_vids/mug_real_5x_side.mp4" style="cursor:pointer;"></video>
            <video data-video="data/real_vids/franka_real_30x_front.mp4" autoplay muted loop playsinline src="data/real_vids/franka_real_30x_front.mp4" style="cursor:pointer;"></video>
            <video data-video="data/real_vids/package_real_5x_side.mp4" autoplay muted loop playsinline src="data/real_vids/package_real_5x_side.mp4" style="cursor:pointer;"></video>
            <video data-video="data/real_vids/drawer_real_5x_side.mp4" autoplay muted loop playsinline src="data/real_vids/drawer_real_5x_side.mp4" style="cursor:pointer;"></video>
            <video data-video="data/real_vids/tiger_real_5x_side.mp4" autoplay muted loop playsinline src="data/real_vids/tiger_real_5x_side.mp4" style="cursor:pointer;"></video>
          </div>
          <div class="carousel-arrow right" id="physical-carousel-right">&#8594;</div>
        </div>

        <div class="carousel-hint">Click a thumbnail to change the video above.</div>
      </section>
      <p class="paragraph">
        We train and evaluate two modern robot visuomotor policies (<a href="https://www.physicalintelligence.company/research/fast">π<sub>0</sub>-FAST</a> and <a href="https://diffusion-policy.cs.columbia.edu/">Diffusion Policy</a>) on either only rendered data generated by <b><span style="color: #003262;">Real2Render2Real</span></b>  or only <b><span style="color: #FDB515;">human teleoperated data</span></b> across 5 manipulation tasks.
      </p>
    <section id="scaling">
      <h2>Performance Scaling</h2>
      <div style="display: flex; justify-content: center; width: 100%; margin: 2rem 0;">
        <img src="data/r2r2r_fig_no_bg.png" alt="Performance Plot" style="max-width: 900px; width: 100%; border-radius: 4px; box-shadow: 0 0 0px rgba(0,0,0,0.0)">
      </div>
      <p>Comparative analysis of imitation-learning policies trained on R2R2R-generated data against human teleoperation data across 1050 physical robot experiments and 5 robotic tasks suggest that while real data is higher quality and
        more efficient per demonstration, R2R2R’s generation enables scaling trajectory diversity far beyond
        human throughput, achieving competitive final performance with less collection effort.</p>
    </section>

    <section id="reconstruction">
      <h2>Scan, Track, Render</h2>
      <!-- Main Iframe and Video Thumbnails as Interactive Selector -->
      <div style="display: flex; flex-direction: column; align-items: center; width: 100%;">
        <div class="iframe-container" style="margin-bottom: 0.75rem;">
          <iframe id="main-iframe" src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/faucet_recording_20250507_110111.viser&initialCameraPosition=1.026,0.455,0.651&initialCameraLookAt=0.108,-0.143,-0.040&initialCameraUp=-0.000,-0.000,1.000" style="width: 100%; max-width: 100%; height: 460px; border: 1px solid #ccc; border-radius: 8px; box-shadow: 0 0 8px rgba(0, 0, 0, 0.1);"></iframe>
          <div class="click-and-move-overlay">
            <img src="data/drag_icon.png" alt="" class="inline-image">
            Click and move me!
            <img src="data/drag_icon.png" alt="" class="inline-image">
          </div>
        </div>
        <div class="carousel-wrapper">
          <div class="carousel-arrow left" id="iframe-carousel-left">&#8592;</div>
          <div class="video-carousel" id="iframe-thumbnails">
            <video data-iframe="0" autoplay muted loop playsinline src="data/demo_vids/faucet_demo.mp4" style="cursor:pointer;"></video>
            <video data-iframe="1" autoplay muted loop playsinline src="data/demo_vids/package_demo.mp4" style="cursor:pointer;"></video>
            <video data-iframe="2" autoplay muted loop playsinline src="data/demo_vids/drawer_reversed_demo.mp4" style="cursor:pointer;"></video>
            <video data-iframe="3" autoplay muted loop playsinline src="data/demo_vids/mug_demo.mp4" style="cursor:pointer;"></video>
            <video data-iframe="4" autoplay muted loop playsinline src="data/demo_vids/tiger_demo.mp4" style="cursor:pointer;"></video>
          </div>
          <div class="carousel-arrow right" id="iframe-carousel-right">&#8594;</div>
        </div>
        <div class="carousel-hint">Click a thumbnail to change the interactive view above.</div>
      </div>
      <!-- <div style="display: flex; gap: 1rem; width: 100%; margin-top: 1rem;">
        <iframe src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/faucet_recording_20250507_110111.viser&initialCameraPosition=1.026,0.455,0.651&initialCameraLookAt=0.108,-0.143,-0.040&initialCameraUp=-0.000,-0.000,1.000" style="flex: 1 1 48%; height: 360px; border: 1px solid #ccc; border-radius: 8px;"></iframe>
        <iframe src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/drawer_reversed_demo_pair.viser&initialCameraPosition=1.026,0.455,0.651&initialCameraLookAt=0.108,-0.143,-0.040&initialCameraUp=-0.000,-0.000,1.000" style="flex: 1 1 48%; height: 360px; border: 1px solid #ccc; border-radius: 8px;"></iframe>
      </div> -->
    </section>
    
    <section id="simulation-vs-rendering">
      <h3>The distinction we make between simulation and rendering is often a point of confusion:</h3>
      <p>  When we refer to <b>simulation</b>, we mean the use of a physics engine to computationally model 
        dynamic interactions. In contrast, <b>rendering</b> refers to generating visual data from a graphics 
        engine.
        <table>
        <tr>
          
        </tr>
      </table>
    </section>
    <section id="why-no-dynamics">
      <h3><span class="toggle-btn" onclick="toggleDynamics()">Why No Dynamics Simulation? &#9662</span><span id="dynamics-expand-hint" style="font-size: 0.8rem; margin-left: 8px; color: #424242;">(click to expand)</span></h2>
      <div id="dynamics-content" style="display: none; max-height: 0; overflow: hidden; transition: max-height 0.5s ease-out;">
        <p>
          In early experiments, we explored physics engines for real-to-sim-to-real data generation but found that with imperfect or unrefined real-to-sim assets, simulated dynamics often diverged from real-world behavior—especially in gripper-object interactions, where issues like interpenetration and unrealistic collisions were common. Still, we wanted to pursue scalable, high-quality data generation through computation. To that end, we use <a href="https://isaac-sim.github.io/IsaacLab/main/index.html">IsaacLab</a> while disregarding its collision computation features, relying on it solely for photorealistic rendering. Object motion is grounded by distilling object-centric dynamics from real-world demonstration videos and object visual appearance is distilled from high-fidelity 3D reconstructions.

          This paper is not a critique of physics engines or their role in robot manipulation, but rather a positive result: computational data generation can scale effectively even without yet simulating dynamics!
        </p>
      </div>
      <script>
        function toggleDynamics() {
          const content = document.getElementById('dynamics-content');
          const btn = document.querySelector('#why-no-dynamics .toggle-btn');
          const hint = document.getElementById('dynamics-expand-hint');
          if (content.style.display === 'none') {
            content.style.display = 'block';
            setTimeout(() => {
              content.style.maxHeight = content.scrollHeight + "px";
            }, 10);
            btn.innerHTML = 'Why No Dynamics Simulation? &#9652';
            hint.style.display = 'none'; // Hide the hint after expanding
          } else {
            content.style.maxHeight = '0';
            setTimeout(() => {
              content.style.display = 'none';
            }, 500); // Wait for transition to complete
            btn.innerHTML = 'Why No Dynamics Simulation? &#9662';
          }
        }
      </script>
    </section>

    <section id="iframes">
  <h2>Rendering More Embodiments</h2>
  <p>Part trajectories from a single demonstration can be retargeted across different robot embodiments.</p>
  <div class="iframe-pair">
    <iframe src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/coffee_maker_recording_20250506_191701.viser&initialCameraPosition=1.009,0.430,0.637&initialCameraLookAt=0.240,-0.160,-0.081&initialCameraUp=-0.000,-0.000,1.000" width="480" height="340"></iframe>
    <iframe src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/franka_coffee_maker_recording_20250506_210619.viser&initialCameraPosition=0.991,-0.089,0.591&initialCameraLookAt=0.000,0.000,0.000&initialCameraUp=-0.000,-0.000,1.000" width="480" height="340"></iframe>
 </div>
 <div class="iframe-pair">
  <video src="data/real_vids/mug_real_5x_side.mp4" autoplay muted loop playsinline style="max-width: 345px;border-radius: 6px;"></video>
  <video src="data/real_vids/franka_real_30x_front.mp4" autoplay muted loop playsinline style="max-width: 345px;border-radius: 6px;"></video>
 </div>
</section>

    <section id="randomization">
      <h2>Domain Randomization</h2>
      <p>We randomize initial object poses, lighting, and camera poses to generate diverse synthetic rollouts for each object-task combination.</p>
      <div class="video-carousel">
        <video autoplay muted loop playsinline src="data/randomization/faucet_rand_range.mp4"></video>
        <video autoplay muted loop playsinline src="data/randomization/package_rand_range.mp4"></video>
        <video autoplay muted loop playsinline src="data/randomization/drawer_rand_range.mp4"></video>
        <video autoplay muted loop playsinline src="data/randomization/mug_rand_range.mp4"></video>
        <video autoplay muted loop playsinline src="data/randomization/tiger_rand_range.mp4"></video>
        <video autoplay muted loop playsinline src="data/randomization/franka_rand_range.mp4"></video>
      </div>
    </section>

    <section id="trajectories">
      <h2>Trajectory Interpolation</h2>
      <p>From a single demonstration, R2R2R generates a distribution of plausible trajectories by interpolating 6-DoF part motion.</p>
      <img src="data/traj_interp.png" alt="Trajectory Interpolation" style="border: 1px solid #ccc;">
      <div class="iframe-container" style="margin-bottom: 0.75rem;">
        <iframe id="main-iframe" src="https://uynitsuj.github.io/viser-client/?playbackPath=https://uynitsuj.github.io/recordings/traj_interp.viser&initialCameraPosition=-0.093,-0.795,0.870&initialCameraLookAt=-0.338,-0.272,-0.111&initialCameraUp=-0.000,-0.000,1.000" style="width: 100%; max-width: 100%; height: 460px; border: 1px solid #ccc; border-radius: 8px; box-shadow: 0 0 8px rgba(0, 0, 0, 0.1);"></iframe>
        <div class="click-and-move-overlay">
          <img src="data/drag_icon.png" alt="" class="inline-image">
          Click and move me!
          <img src="data/drag_icon.png" alt="" class="inline-image">
        </div>
      </div>

    </section>

    <section id="description-video">
      <h2>Full Project Video</h2>
      <div style="display: flex; justify-content: center; width: 100%; margin-bottom: 1rem;">
        <iframe src="https://drive.google.com/file/d/1kwoy75F_KsiVilJQNh9A2s5ZdIYCKHjk/preview" style="width: 600px; height: 320px;" allow="autoplay; fullscreen" allowfullscreen></iframe>
      </div>
    </section>

    <section id="bibtex">
      <h2>BibTeX</h2>
      <div style="position: relative; display: inline-block; width: 100%;">
        <pre><code>@misc{yu2025real2render2realscalingrobotdata,
        title={Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware},
        author={Justin Yu and Letian Fu and Huang Huang and Karim El-Refai and Rares Andrei Ambrus and Richard Cheng and Muhammad Zubair Irshad and Ken Goldberg},
        year={2025},
        eprint={2505.09601},
        archivePrefix={arXiv},
        primaryClass={cs.RO},
        url={https://arxiv.org/abs/2505.09601},
  }</code></pre>
        <button class="copy-button" onclick="copyBibtex()">Copy BibTeX</button>
      </div>
      <script>
        function copyBibtex() {
          const bibtexText = document.querySelector('#bibtex pre code').innerText;
          navigator.clipboard.writeText(bibtexText)
            .then(() => {
              const button = document.querySelector('.copy-button');
              button.textContent = 'Copied!';
              setTimeout(() => {
                button.textContent = 'Copy BibTeX';
              }, 2000);
            })
            .catch(err => {
              console.error('Failed to copy: ', err);
            });
        }
      </script>
      <style>
        #bibtex pre {
          font-size: 0.9em;
          position: relative;
          padding: 1em;
          background-color: #2c2c2c;
          color: #ddd;
          border-radius: 4px;
          /* border: 1px solid #181a1f; */
        }
        #bibtex pre code {
          display: block;
          overflow-x: auto;
        }
        .copy-button {
          position: absolute;
          top: 20px;
          right: 10px;
          width: 30px;
          height: 30px;
          background-color: rgba(255, 255, 255, 0.7);
          border: 1px solid #ddd;
          border-radius: 4px;
          cursor: pointer;
          display: flex;
          align-items: center;
          justify-content: center;
          font-size: 0;
          opacity: 0.6;
          transition: opacity 0.2s;
        }
        .copy-button:hover {
          opacity: 1;
        }
        .copy-button::before {
          content: "";
          display: inline-block;
          width: 16px;
          height: 16px;
          background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='%23333'%3E%3Cpath d='M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z'/%3E%3C/svg%3E");
          background-size: contain;
          background-repeat: no-repeat;
        }
      </style>
    </section>
    <footer>
      &copy; Webpage designed by the Real2Render2Real team, inspired by the <a href="https://www.videomimic.net/">VideoMimic</a> website.
    </footer>
    </div>
  </main>
</body>
</html>
